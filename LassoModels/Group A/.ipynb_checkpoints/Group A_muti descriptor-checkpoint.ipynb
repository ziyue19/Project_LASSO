{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wear predition \n",
    "## <font color=\"#dd0000\">Group A</font> --  multi descriptor\n",
    "### generating and screening **unary** descriptor by *LASSO+L0*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'combine_features'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-d9c54af1561c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcombine_features\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilterwarnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ignore'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mode.use_inf_as_na'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'combine_features'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from itertools import combinations\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt \n",
    "import scipy.stats as ss\n",
    "import warnings\n",
    "from collections import Counter\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from IPython.display import HTML\n",
    "from jupyter_jsmol import JsmolView\n",
    "import itertools\n",
    "import functools\n",
    "import math\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "import combine_features as cf\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('mode.use_inf_as_na', True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print (os.path.abspath('.'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"groupA.csv\")\n",
    "df.head()\n",
    "ColNames = df.columns\n",
    "print(ColNames)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns={'ETF\\n(104 Pa)':'ETF(MPa)'},inplace=True)\n",
    "df['ETF(MPa)']=df['ETF(MPa)']/100 # 把etf的单位变为mpa\n",
    "df.columns=['Sample No.','Hv','UTS','YS','UE','ETF','K','n','WL']\n",
    "df['UE']=df['UE']/100 # 把ue变成小数\n",
    "df['Hv']=df['Hv']*9.8  #change the unit of Hv into MPa\n",
    "#df.to_excel(\"/Users/zy/Desktop/lasso+l0_abrasion_FV/GA_data.xls\", index=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['Sample No.'],axis=1,inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一、定义operations set{+,-,*,/,^2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##二元函数\n",
    "_my_sum = lambda x:np.sum(x)\n",
    "_my_diff= lambda x:np.diff(x)\n",
    "_my_abs_diff= lambda x:np.abs(_my_diff(x))\n",
    "\n",
    "_my_power_2=lambda x: np.power(x,2)\n",
    "#_my_power_3=lambda x: x**3\n",
    "\n",
    "\n",
    "def _my_div(x):\n",
    "    return x[0]/x[1]\n",
    "_my_mul= lambda x:np.prod(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "##一元函数\n",
    "# _my_exp=lambda x: np.exp(x)\n",
    "# _my_log= lambda x : math.log(x)\n",
    "def _my_power_n(x):\n",
    "    \n",
    "    a=np.power(x,df['n'])\n",
    "    a.astype(np.int)\n",
    "    #print(a.dtype)\n",
    "    return a\n",
    "def _my_sum_power_2(x):\n",
    "    return np.square(_my_sum(x))\n",
    "def _my_diff_power_2(x):\n",
    "    return np.square(_my_diff(x))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_features(df=None, allowed_operations=None, is_print=True):\n",
    "### generate combinatons of features by given a dataframe and a list of allowed operations.\n",
    "    if is_print:\n",
    "        if allowed_operations:\n",
    "            print('Selected operations:\\\\n {0}'.format(allowed_operations))\n",
    "        else:\n",
    "            print('No allowed operations selected.')\n",
    "        columns_ = df.columns.tolist()\n",
    "    dict_features={\n",
    "        ## 变量分类\n",
    "        'UTS':'a1',\n",
    "        'YS':'a1',\n",
    "        'ETF':'a1',\n",
    "        'K':'a1',\n",
    "        'Hv':'a1', \n",
    "        \n",
    "        'UE':'a2',\n",
    "        'n':'a2',\n",
    "    \n",
    "        }\n",
    "    df_a1 = df[[col for col in columns_ if dict_features.get(col.split('(', 1)[0])=='a1']].astype('float32')\n",
    "    df_a2 = df[[col for col in columns_ if dict_features.get(col.split('(', 1)[0])=='a2']].astype('float32')\n",
    "  \n",
    "    col_a1 = df_a1.columns.tolist()\n",
    "    col_a2 = df_a2.columns.tolist()\n",
    "\n",
    "    ## this list will at the end all the dataframes created\\n',\n",
    "    df_list = []\n",
    "    \n",
    "    df_b1_list = []\n",
    "    df_b2_list = []\n",
    "    df_c1_list = []\n",
    "    df_c2_list = []\n",
    "    df_d1_list = []\n",
    "    df_d2_list = []\n",
    "    df_e_list = []\n",
    "    df_f_list = []\n",
    "    df_g_list = []\n",
    "\n",
    "    \n",
    "    df_x1_list = []\n",
    "    df_x2_list = []\n",
    "    df_y1_list = []\n",
    "    df_y2_list = []\n",
    "    df_z_list = []\n",
    "\n",
    "    # create b1: absolute differences and sums of a1\n",
    "    for subset in itertools.combinations(col_a1,2):\n",
    "        if '+' in allowed_operations:\n",
    "            cols = ['('+subset[0]+'+'+subset[1]+')']\n",
    "            data = df_a1[list(subset)].apply(_my_sum,axis=1)\n",
    "            df_b1_list.append(pd.DataFrame(data,columns=cols))\n",
    "            \n",
    "#         if '-' in allowed_operations:\n",
    "#             cols = ['('+subset[1]+'-'+subset[0]+')']\n",
    "#             data = df_a1[list(subset)].apply(_my_diff,axis=1)\n",
    "#             df_b1_list.append(pd.DataFrame(data,columns=cols))\n",
    "            \n",
    "        if '|-|' in allowed_operations:\n",
    "            cols = ['|'+subset[1]+'-'+subset[0]+'|']\n",
    "            data = df_a1[list(subset)].apply(_my_abs_diff,axis=1)\n",
    "            df_b1_list.append(pd.DataFrame(data,columns=cols))\n",
    "            \n",
    "                   \n",
    "    #create b2: abs diff and sums of a2:\n",
    "    for subset in itertools.combinations(col_a2,2):\n",
    "        if '+' in allowed_operations:\n",
    "            cols = ['('+subset[0]+'+'+subset[1]+')']\n",
    "            data = df_a2[list(subset)].apply(_my_sum,axis=1)\n",
    "            df_b2_list.append(pd.DataFrame(data,columns=cols))\n",
    "\n",
    "            \n",
    "#         if '-' in allowed_operations:\n",
    "#             cols = ['('+subset[1]+'-'+subset[0]+')']\n",
    "#             data = df_a2[list(subset)].apply(_my_diff,axis=1)\n",
    "#             df_b2_list.append(pd.DataFrame(data,columns=cols))\n",
    "\n",
    "            \n",
    "        if '|-|' in allowed_operations:\n",
    "            cols = ['|'+subset[1]+'-'+subset[0]+'|']\n",
    "            data = df_a2[list(subset)].apply(_my_abs_diff,axis=1)\n",
    "            df_b2_list.append(pd.DataFrame(data,columns=cols))\n",
    "            \n",
    "    # create c1:^2 of a1:\n",
    "    for subset in itertools.combinations(col_a1,1):\n",
    "\n",
    "        if '^2' in allowed_operations:\n",
    "            cols = ['('+subset[0]+'^2'+')']       \n",
    "            f = df_a1[list(subset)].apply(_my_power_2,axis=1)\n",
    "            data=f.values\n",
    "            df_c1_list.append(pd.DataFrame(data,columns=cols))\n",
    "#         if '^3' in allowed_operations:\n",
    "#             cols = ['('+subset[0]+'^3'+')']       \n",
    "#             f = df_a1[list(subset)].apply(_my_power_3,axis=1)\n",
    "#             data=f.values\n",
    "#             df_c1_list.append(pd.DataFrame(data,columns=cols))\n",
    "            \n",
    "    # create c2:^2 of a2:\n",
    "    for subset in itertools.combinations(col_a2,1):\n",
    "\n",
    "        if '^2' in allowed_operations:\n",
    "            cols = ['('+subset[0]+'^2'+')']       \n",
    "            f = df_a2[list(subset)].apply(_my_power_2,axis=1)\n",
    "            data=f.values\n",
    "            df_c2_list.append(pd.DataFrame(data,columns=cols))\n",
    "#         if '^3' in allowed_operations:\n",
    "#             cols = ['('+subset[0]+'^3'+')']       \n",
    "#             f = df_a2[list(subset)].apply(_my_power_3,axis=1)\n",
    "#             data=f.values\n",
    "#             df_c2_list.append(pd.DataFrame(data,columns=cols))\n",
    "\n",
    "    # create d1:^2 of b1:               \n",
    "    for subset in itertools.combinations(col_a1, 2):\n",
    "\n",
    "        if '^2' in allowed_operations:\n",
    "            cols = ['('+subset[0]+'+'+subset[1]+')'+'^2']       \n",
    "            f = df_a1[list(subset)].apply(_my_sum_power_2,axis=1)\n",
    "            data=f.values\n",
    "            df_d1_list.append(pd.DataFrame(data,columns=cols))\n",
    "            cols = ['('+subset[0]+'-'+subset[1]+')'+'^2']       \n",
    "            f = df_a1[list(subset)].apply(_my_diff_power_2,axis=1)\n",
    "            data=f.values\n",
    "            df_d1_list.append(pd.DataFrame(data,columns=cols))\n",
    "       \n",
    "    # create d2:^2 of b2:\n",
    "    for subset in itertools.combinations(col_a2, 2):\n",
    "\n",
    "        if '^2' in allowed_operations:\n",
    "            cols = ['('+subset[0]+'+'+subset[1]+')'+'^2']       \n",
    "            f = df_a2[list(subset)].apply(_my_sum_power_2,axis=1)\n",
    "            data=f.values\n",
    "            df_d2_list.append(pd.DataFrame(data,columns=cols))\n",
    "            cols = ['('+subset[0]+'-'+subset[1]+')'+'^2']       \n",
    "            f = df_a2[list(subset)].apply(_my_diff_power_2,axis=1)\n",
    "            data=f.values\n",
    "            df_d2_list.append(pd.DataFrame(data,columns=cols))\n",
    "            \n",
    "\n",
    "             \n",
    "        \n",
    "    if not df_a1.empty: \n",
    "        df_x1_list.append(df_a1)\n",
    "        df_y1_list.append(df_a1)\n",
    "        #df_z_list.append(df_a1)\n",
    "        df_list.append(df_a1)\n",
    "        \n",
    "    if not df_a2.empty: \n",
    "        df_x1_list.append(df_a2)\n",
    "        df_y1_list.append(df_a2)\n",
    "        #df_z_list.append(df_a2)\n",
    "        df_list.append(df_a2)\n",
    "\n",
    "        \n",
    "    if df_b1_list: \n",
    "        df_b1 = pd.concat(df_b1_list, axis=1)\n",
    "        col_b1 = df_b1.columns.tolist()\n",
    "        df_x1_list.append(df_b1)\n",
    "        df_list.append(df_b1)\n",
    "\n",
    "    if df_b2_list: \n",
    "        df_b2 = pd.concat(df_b2_list, axis=1)\n",
    "        col_b2 = df_b2.columns.tolist()\n",
    "        df_x1_list.append(df_b2)\n",
    "        df_list.append(df_b2)\n",
    "        \n",
    "    if df_c1_list: \n",
    "        df_c1 = pd.concat(df_c1_list, axis=1)\n",
    "        col_c1 = df_c1.columns.tolist()\n",
    "        df_x1_list.append(df_c1)\n",
    "        df_y1_list.append(df_c1)\n",
    "        #df_z_list.append(df_c1)\n",
    "        df_list.append(df_c1)\n",
    "    if df_c2_list: \n",
    "        df_c2 = pd.concat(df_c2_list, axis=1)\n",
    "        col_c2 = df_c2.columns.tolist()\n",
    "        df_x1_list.append(df_c2)\n",
    "        df_y1_list.append(df_c2)\n",
    "        #df_z_list.append(df_c2)\n",
    "        df_list.append(df_c2)\n",
    "    if df_d1_list: \n",
    "        df_d1 = pd.concat(df_d1_list, axis=1)\n",
    "        col_d1 = df_d1.columns.tolist()\n",
    "        df_x1_list.append(df_d1)\n",
    "        df_list.append(df_d1)\n",
    "    if df_d2_list: \n",
    "        df_d2 = pd.concat(df_d2_list, axis=1)\n",
    "        col_d2 = df_d2.columns.tolist()\n",
    "        df_x1_list.append(df_d2)\n",
    "        df_list.append(df_d2)\n",
    "        \n",
    "    if df_x1_list:\n",
    "        df_x1 = pd.concat(df_x1_list, axis=1)\n",
    "        col_x1 = df_x1.columns.tolist()\n",
    "        \n",
    "    if df_x2_list:\n",
    "        df_x2 = pd.concat(df_x2_list, axis=1)\n",
    "        col_x2 = df_x2.columns.tolist()\n",
    "        \n",
    "        \n",
    "    if df_y1_list:\n",
    "        df_y1 = pd.concat(df_y1_list, axis=1)\n",
    "        col_y1 = df_y1.columns.tolist()\n",
    "        \n",
    "    if df_y2_list:\n",
    "        df_y2 = pd.concat(df_y2_list, axis=1)\n",
    "        col_y2 = df_y2.columns.tolist()\n",
    "    if df_z_list:\n",
    "        df_z = pd.concat(df_z_list, axis=1)\n",
    "        col_z = df_z.columns.tolist()\n",
    "        \n",
    "    #create e: mul within X1:\n",
    "    for subset in itertools.combinations(col_x1,2):\n",
    "                if '*' in allowed_operations:\n",
    "                    #print(subset[0],subset[1])\n",
    "                    cols = [subset[0]+'*'+subset[1]] \n",
    "                    #now the operation is between two dataframes\\n',\n",
    "                    data = df_x1[list(subset)].apply(_my_mul, axis=1)  \n",
    "                    df_e_list.append(pd.DataFrame(data, columns=cols)) \n",
    "\n",
    "                if '/' in allowed_operations:\n",
    "                    cols = [subset[0]+'/'+subset[1]] \n",
    "                    #now the operation is between two dataframes\\n',\n",
    "                    data = df_x1[list(subset)].apply(_my_div, axis=1) \n",
    "                    df_e_list.append(pd.DataFrame(data, columns=cols)) \n",
    "                    #reverse\n",
    "                    cols = [subset[1]+'/'+subset[0]] \n",
    "                    data = df_x1[list(subset)].apply(_my_div, axis=1) \n",
    "                    df_e_list.append(pd.DataFrame(data, columns=cols)) \n",
    "    if df_e_list:\n",
    "        df_e = pd.concat(df_e_list, axis=1)\n",
    "        col_e = df_e.columns.tolist()\n",
    "                    \n",
    "    #create f: mul and ratios of x1 with {a1, a2, c1, c2}:\n",
    "    if df_y1_list and df_e_list:    \n",
    "        for sub_y1 in col_y1:\n",
    "            for sub_e in col_e:\n",
    "                #print(sub_y1)\n",
    "                #print(sub_e)\n",
    "                if '*' in allowed_operations:\n",
    "                    cols = [sub_y1+'*'+'('+sub_e+')'] \n",
    "                    #now the operation is between two dataframes\\n',\n",
    "                    data=df_y1[sub_y1].multiply(df_e[sub_e])\n",
    "                    df_f_list.append(pd.DataFrame(data, columns=cols)) \n",
    "                if '/' in allowed_operations:\n",
    "                    cols = [sub_y1+'/'+'('+sub_e+')'] \n",
    "                    #now the operation is between two dataframes\\n',\n",
    "                    data=df_y1[sub_y1].divide(df_e[sub_e])\n",
    "                    df_f_list.append(pd.DataFrame(data, columns=cols)) \n",
    "                    #reverse\n",
    "                    cols = ['('+sub_e+')'+'/'+sub_y1] \n",
    "                    data=df_e[sub_e].divide(df_y1[sub_y1])\n",
    "                    df_f_list.append(pd.DataFrame(data, columns=cols)) \n",
    "#     if df_f_list:\n",
    "#         df_f = pd.concat(df_f_list, axis=1)\n",
    "#         col_f = df_f.columns.tolist()\n",
    "#     if df_z_list:\n",
    "#         df_z = pd.concat(df_z_list, axis=1)\n",
    "#         col_z = df_z.columns.tolist()\n",
    "#     #print(df_f.info(),df_z.info())\n",
    "#     #print(df_z)\n",
    "    \n",
    "        \n",
    "#     #create g: mul and ratios of f with {a1, a2, c1, c2}:\n",
    "#     if df_f_list and df_z_list:    \n",
    "#         for sub_f in col_f:\n",
    "#             for sub_z in col_z:\n",
    "#                 if '*' in allowed_operations:\n",
    "#                     cols = ['('+sub_f+')'+'*'+'('+sub_z+')'] \n",
    "#                     #now the operation is between two dataframes\\n',\n",
    "#                     data=df_f[sub_f].multiply(df_z[sub_z])\n",
    "#                     df_g_list.append(pd.DataFrame(data, columns=cols)) \n",
    "#                 if '/' in allowed_operations:\n",
    "#                     cols = ['('+sub_f+')'+'/'+'('+sub_z+')'] \n",
    "#                     #now the operation is between two dataframes\\n',\n",
    "#                     data=df_f[sub_f].divide(df_z[sub_z])\n",
    "#                     df_g_list.append(pd.DataFrame(data, columns=cols)) \n",
    "#                     #reverse\n",
    "#                     cols = ['('+sub_z+')'+'/'+'('+sub_f+')'] \n",
    "#                     data=df_z[sub_z].divide(df_f[sub_f])\n",
    "#                     df_g_list.append(pd.DataFrame(data, columns=cols)) \n",
    "                    \n",
    "#     if df_d_list:\n",
    "#         df_d=pd.concat(df_d_list,axis=1)\n",
    "#         col_d=df_d.columns.tolist()\n",
    "#         df_list.append(df_d)\n",
    "    if df_e_list:\n",
    "        df_e=pd.concat(df_e_list,axis=1)\n",
    "        col_e=df_e.columns.tolist()\n",
    "        df_list.append(df_e)\n",
    "    if df_f_list:\n",
    "        df_f=pd.concat(df_f_list,axis=1)\n",
    "        col_f=df_f.columns.tolist()\n",
    "        df_list.append(df_f)\n",
    "#     if df_g_list:\n",
    "#         df_g=pd.concat(df_g_list,axis=1)\n",
    "#         col_g=df_g.columns.tolist()\n",
    "#         df_list.append(df_g)\n",
    "\n",
    "    if df_list:\n",
    "        df_combined_features = pd.concat(df_list, axis=1)\n",
    "        #print(len(df_b1_list),len(df_b2_list),len(df_d_list),len(df_e_list))\n",
    "    elif is_print:\n",
    "        print('No features selected. Please select at least two primary features.')\n",
    "\n",
    "\n",
    "    if is_print:\n",
    "        print('Number of total features generated: {0}'.format(df_combined_features.shape[1]))\n",
    "\n",
    "    return df_combined_features \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(selected_feature_list, allowed_operations):\n",
    "    # extract WEARLOSS and selected features from df_data \n",
    "    P = df['WL'].values\n",
    "    df_features = df[selected_feature_list]\n",
    "    \n",
    "    # derive new features using allowed_operations\n",
    "    df_combined = combine_features(df=df_features, allowed_operations=allowed_operations)\n",
    "    return P, df_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import Data\n",
    "selected_feature_list = ['UE','Hv','UTS','YS','n','ETF','K']\n",
    "allowed_operations = ['+','-','|-|','/','*','^2']\n",
    "\n",
    "\n",
    "\n",
    "P, df_D = get_data(selected_feature_list, allowed_operations)\n",
    "print(len(list(df_D)))\n",
    "df_D.replace([np.inf, -np.inf], np.nan,inplace=True)\n",
    "df_D =df_D.dropna(axis=1)\n",
    "df_D = df_D.loc[:, (df_D != 0).any(axis=0)]\n",
    "\n",
    "print(len(list(df_D)))\n",
    "\n",
    "\n",
    "D = df_D.values\n",
    "D = D.astype(np.float64)\n",
    "features_list = df_D.columns.tolist()\n",
    "df_D.info()\n",
    "df_D.isna().values.any()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_D=pd.DataFrame(df_D,dtype=np.float)\n",
    "df_D.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.set_option('display.width', 10)  # 设置字符显示宽度\n",
    "# pd.set_option('display.max_rows', None)  # 设置显示最大行\n",
    "# print(df_D.iloc[0])\n",
    "# df_D.iloc[0].isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standardize data\n",
    "D_standardized = ss.zscore(D)\n",
    "print(D_standardized.shape)\n",
    "print(type(D_standardized))\n",
    "np.isnan(D_standardized).any()\n",
    "#print(np.isnan(D_standardized).any(axis=0))\n",
    "D_standardized=D_standardized[:, ~np.isnan(D_standardized).any(axis=0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse_cv(model):\n",
    "    rmse= np.sqrt(-cross_val_score(model, D_standardized, P, \n",
    "                                   scoring=\"neg_mean_squared_error\", cv = 5))\n",
    "    return(rmse)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ##cv调参2\n",
    "# # 根据上图建立Lasso进行alpha选择的范围\n",
    "# alpha_range = np.linspace(0.1,0.001,70)\n",
    "\n",
    "# # # LassoCV\n",
    "# lasso_ = LassoCV(alphas=alpha_range,cv=5).fit(D_standardized,P)\n",
    "\n",
    "# # # 查看最佳正则化系数\n",
    "# best_alpha = lasso_.alpha_ \n",
    "# print(best_alpha)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse():\n",
    "    \n",
    "    P_predict = lasso.predict(D_standardized)\n",
    "    #print(P_predict)\n",
    "    RMSE_LASSO = np.linalg.norm(P-P_predict) / np.sqrt(20.)\n",
    "    return RMSE_LASSO\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "def r_2():\n",
    "    P_predict = lasso.predict(D_standardized)\n",
    "    return r2_score(P_predict,P)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #以线性关系改变lambda的值，观察非零系数的个数\n",
    "# from sklearn.linear_model import Lasso\n",
    "# alpha = np.linspace(0.04,0.002,9)\n",
    "# m=0\n",
    "# lams=[]\n",
    "# rmse_s=[]\n",
    "# #table = PrettyTable(['NO.','alpha', 'num_nonzero','selected features','rmse','coef','r^2','intercept'])\n",
    "\n",
    "\n",
    "# for i in range(90):\n",
    "#     global m\n",
    "#     lasso=Lasso(alpha=alpha[i])\n",
    "#     lasso.fit(D_standardized,P)\n",
    "#     coef=lasso.coef_\n",
    "#     a=np.sum(coef != 0)\n",
    "    \n",
    "#     if a!=m:\n",
    "#         m=a\n",
    "        \n",
    "# #         print(m)\n",
    "# #         print(alpha[i])\n",
    "\n",
    "        \n",
    "#     # get strings of selected features\n",
    "#         selected_indices = lasso.coef_.nonzero()[0]\n",
    "#         selected_features = [features_list[i] for i in selected_indices]\n",
    "#         #print(lasso.predict(D_standardized))\n",
    "#         #print(pd.DataFrame({'alpha':\"%.3f\" %alpha[i],'num_nonzero':m,'features_list':selected_features,'rmse':rmse_cv(),'coef':coef[coef.nonzero()].round(3)}))\n",
    "#         #print('alpha',\"%.3f\" %alpha[i],'num_nonzero',m,selected_features,'rmse',rmse_cv(),'coef',coef[coef.nonzero()].round(5))\n",
    "#         #pd.Series(index = ['Intercept'] + D_standardized.columns.tolist(),data = [lasso.intercept_] + lasso.coef_.tolist())\n",
    "#         #print(lasso.intercept_)\n",
    "#         if a<=10:\n",
    "#             #table.add_row([i,alpha[i].round(2),m,selected_features,rmse().round(2),coef[coef.nonzero()].round(2),lasso.intercept_.round(2),r_2()])\n",
    "#             print('alpha',\"%.5f\" %alpha[i],'num_nonzero',m,selected_features,'rmse',rmse().round(4),'coef',coef[coef.nonzero()].round(5),'截距:',lasso.intercept_.round(2),'\\n','r_squared:',r_2().round(5))\n",
    "            \n",
    "#             rmse_s.append(rmse)\n",
    "#             lams.append(alpha[i])\n",
    "\n",
    "\n",
    "\n",
    "# # print(\"lambda: %.3f\\t dimension of descriptor: %s\\t RMSE_LASSO: %.3f\\t RMSE_LS: %.3f\" \n",
    "# #       %(lam, len(selected_features), RMSE_LASSO, RMSE_LS))\n",
    "# # print(pd.DataFrame({'features':np.array(selected_features), 'abs(nonzero_coefs_LASSO)': np.abs(coef[coef.nonzero()])}))\n",
    "# # plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Lasso(0.02575).fit(D_standardized,P)\n",
    "coef=model.coef_\n",
    "a=np.sum(coef != 0)\n",
    "selected_indices = model.coef_.nonzero()[0]\n",
    "selected_features = [features_list[i] for i in selected_indices]\n",
    "#print('num_nonzero',a,selected_features,'rmse',rmse(),'coef',coef[coef.nonzero()].round(8),'截距:',model.intercept_)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(selected_features)\n",
    "D_screened=df_D[selected_features]\n",
    "D_= D_screened.values\n",
    "D_= D_.astype(np.float64)\n",
    "D_screened.info()\n",
    "D_screened_standardized = ss.zscore(D_)\n",
    "print(len(D_screened_standardized[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L0(P, D, dimension):\n",
    "    n_rows, n_columns = D.shape\n",
    "    D = np.column_stack((D, np.ones(n_rows)))\n",
    "    SE_min = np.inner(P ,P)\n",
    "    coef_min, permu_min = None, None\n",
    "    for permu in combinations(range(n_columns), dimension):\n",
    "        D_ls = D[:, permu + (-1,)]\n",
    "        coef, SE, __1, __2 = np.linalg.lstsq(D_ls, P, rcond=-1)\n",
    "        try:\n",
    "            if SE[0] < SE_min: \n",
    "                SE_min = SE[0]\n",
    "                coef_min, permu_min = coef, permu\n",
    "        except:\n",
    "            pass\n",
    "    RMSE = np.sqrt(SE_min/n_rows)\n",
    "    return RMSE, coef_min, permu_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def L0_predict(coefficients,X,selected_indices):\n",
    "    X = np.array(X)\n",
    "    p=len(X)\n",
    "    y_pred=[]\n",
    "    n=len(selected_indices)\n",
    "    X_selected=np.zeros(shape=((n,p)))\n",
    "    w=coefficients\n",
    "    m=len(coefficients)\n",
    "    print('len(coefs)=',m)\n",
    "\n",
    "    z=0\n",
    "    for j in selected_indices:\n",
    "        #print(X[:,j])\n",
    "        #np.append(X_selected[z,:],X[:,j],axis=1)\n",
    "        X_selected[z,:]=X[:,j]\n",
    "        z=z+1\n",
    "    #print('X_selected',X_selected) \n",
    "    #print('selected indices',n)\n",
    "    for i in range(0,p):\n",
    "        #print(i)\n",
    "#         print('yes')\n",
    "#         print(X_selected[i])\n",
    "#         print(X_selected[i]* w[0:n] + w[n])\n",
    "#         print(w[0:n])\n",
    "#         print(w[n])\n",
    "\n",
    "        #ele=w[0:m-1]*X_selected[:,i]+ w[m-1]\n",
    "        ele=np.dot(w[0:m-1],X_selected[:,i])+w[m-1]\n",
    "        #print(ele)\n",
    "        #print(w[0:m-1],X_selected[:,i],w[m-1])\n",
    "    \n",
    "        y_pred.append(ele.round(4))\n",
    "    #print(type(y_pred))\n",
    "    \n",
    "    \n",
    "    return y_pred\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"     RMSE   best desriptor\")\n",
    "for dim in range(1,2):\n",
    "    RMSE, coefficients, selected_indices_l0 = L0(P,D_screened_standardized,dim)\n",
    "    print(selected_indices_l0)\n",
    "    print(selected_features)\n",
    "    Y_pre=L0_predict(coefficients,D_screened_standardized,selected_indices_l0)\n",
    "    #print(Y_pre)\n",
    "    y_pre= pd.DataFrame(Y_pre, columns=['Predict value'])\n",
    "    y_pre.to_excel('/Users/zy/Desktop/lasso+l0_abrasion_FV/WL_pre_A3.xlsx')\n",
    "    score=r2_score(P,Y_pre)\n",
    "    descriptor=[selected_features[i] for i in selected_indices_l0]\n",
    "    print('%2sD: %.5f' % (dim, RMSE), [selected_features[i] for i in selected_indices_l0],coefficients,'score',score)\n",
    "    df_A_3=df_D[descriptor]\n",
    "    df_A_3.to_excel(\"/Users/zy/Desktop/lasso+l0_abrasion_FV/dfA3.xlsx\")\n",
    "    #print('y_pred:',y_pred(coefficients,D,selected_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
